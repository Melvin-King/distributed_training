# distributed_training
IERG5050 HW2 code repo.

This project implement distributed training methods, including data parallelism and pipeline parallelism across multiple GPUs.

Data for training: https://huggingface.co/datasets/bbaaaa/iwslt14-de-en-preprocess
